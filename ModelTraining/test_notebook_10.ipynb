{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf19772",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34241d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f4bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Memory fix\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "       tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d0fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directories\n",
    "data_dir = 'C:/Users/BITMAP/python/data_rgb/'\n",
    "working_dir = 'C:/Users/BITMAP/python/training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate logger\n",
    "logger = logging.getLogger('tensorflow')\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4956d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "batch_size =16\n",
    "image_height = 128\n",
    "image_width = 128\n",
    "color_mode = 'rgb'\n",
    "no_of_channels = 3\n",
    "epochs = 10\n",
    "#folds = 10\n",
    "split_percentage = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d11ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Must change after every training\n",
    "training_no = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for training\n",
    "training_dir = os.path.join(working_dir, f'training_{training_no}')\n",
    "if not os.path.exists(training_dir):\n",
    "    os.makedirs(training_dir)\n",
    "else:\n",
    "    raise SystemExit(\"Training directory is already created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    class_names=['both', 'crackles', 'wheezes', 'normal'],\n",
    "    image_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode=color_mode)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_train_validation = 1 # Must be same for train_ds and val_ds\n",
    "shuffle_value = True\n",
    "validation_split = 0.25\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "directory ='C:/Users/BITMAP/python/data_rgb/',\n",
    "image_size = (128, 128),\n",
    "validation_split = validation_split,\n",
    "subset = \"training\",\n",
    "seed = seed_train_validation,\n",
    "color_mode = 'rgb',\n",
    "shuffle = shuffle_value)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "directory ='C:/Users/BITMAP/python/data_rgb/',\n",
    "image_size = (128, 128),\n",
    "validation_split = validation_split,\n",
    "subset = \"validation\",\n",
    "seed = seed_train_validation,\n",
    "color_mode = 'rgb',\n",
    "shuffle = shuffle_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "determine how many batches of data are available in the validation set using tf.data.experimental.cardinality, and then move the two-third of them (2/3 of 30% = 20%) to a test set as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(val_ds)\n",
    "test_ds = val_ds.take((2*val_batches) // 3)\n",
    "val_ds = val_ds.skip((2*val_batches) // 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train: \" + str(len(train_ds)))\n",
    "print(\"Val: \" + str(len(val_ds)))\n",
    "print(\"Test: \" + str(len(test_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input = keras.layers.Input(shape=(image_height, image_width, no_of_channels), name=\"input\")\n",
    "x = keras.layers.Rescaling(1./255)(input)\n",
    "x = keras.layers.Conv2D(32, 3, strides=(1, 3), padding='same')(x)\n",
    "x = keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2, padding='valid')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Conv2D(64, 3, strides=(1, 3), padding='same')(x)\n",
    "x = keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2, padding='valid')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "hidden1 = keras.layers.Flatten()(x)\n",
    "\n",
    "hidden1 = keras.layers.Dense(100)(hidden1)\n",
    "hidden1 = keras.layers.LeakyReLU(alpha=0.1)(hidden1)\n",
    "hidden1 = keras.layers.Dropout(0.5)(hidden1)\n",
    "\n",
    "hidden2 = keras.layers.Dense(200)(hidden1)\n",
    "hidden2 = keras.layers.LeakyReLU(alpha=0.1)(hidden2)\n",
    "hidden2 = keras.layers.Dropout(0.5)(hidden2)\n",
    "\n",
    "hidden3 = keras.layers.Dense(100)(hidden2)\n",
    "hidden3 = keras.layers.LeakyReLU(alpha=0.3)(hidden3)\n",
    "hidden3 = keras.layers.Dropout(0.5)(hidden3)\n",
    "\n",
    "output = keras.layers.Dense(4, activation='softmax')(hidden3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed16ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback - if weights don't change after 10 epochs stop training\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Create net for training\n",
    "net= keras.Model(input, output, name=\"CNN\")\n",
    "net.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['sparse_categorical_accuracy'])\n",
    "K.set_value(net.optimizer.learning_rate, 0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3b099",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tf.keras.models.load_model('my_model2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd08fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
    "K.set_value(net.optimizer.learning_rate, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = net.fit(train_ds,  epochs=100, callbacks=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10), validation_data=val_ds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(history.history['sparse_categorical_accuracy']), np.median(history.history['val_sparse_categorical_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = net.evaluate(test_ds)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = net.predict(test_ds)\n",
    "predicted_labels = tf.argmax(predictions, axis=1)\n",
    "\n",
    "true_labels = []\n",
    "for _, labels in test_ds:\n",
    "    true_labels.extend(labels.numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Prediction accuracy: \"+str(accuracy))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', xticklabels=[0, 1, 2], yticklabels=[0, 1, 2])\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save('my_model2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c185daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8921f5",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('my_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e828847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f676b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
    "K.set_value(new_model.optimizer.learning_rate, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nastavimo trenirati taj model. Ponovo ćemo spremiti model jer će se težine u mreži promijeniti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = new_model.fit(train_ds,  epochs=20, callbacks=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10), validation_data=val_ds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(history.history['sparse_categorical_accuracy']), np.median(history.history['val_sparse_categorical_accuracy']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = new_model.evaluate(test_ds)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict(test_ds)\n",
    "predicted_labels = tf.argmax(predictions, axis=1)\n",
    "true_labels = []\n",
    "for _, labels in test_ds:\n",
    "    true_labels.extend(labels.numpy())\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"Prediction accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save('my_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
